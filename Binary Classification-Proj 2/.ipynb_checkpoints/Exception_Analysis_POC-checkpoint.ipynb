{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import plotly.express as px"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Definitions for Exception Codes and Performance Status Codes\n",
    "os.chdir(r\"Insert Data Folder Directory Here\")\n",
    "dimexc = pd.read_excel('vDimException.xlsx', converters={'ExceptionCode':str})\n",
    "dimstatus = pd.read_excel('vDimStatus.xlsx', converters={'PerformStatusCode':str})\n",
    "#also import exceptions_data.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Selects the Top Tracking Numbers from TException that have at least \"4\" exception codes, then merges it with TperformanceData\n",
    "query = \"\"\"\n",
    "SELECT TOP 500000 * FROM [Track].[TException] a\n",
    "INNER JOIN( SELECT TrackingNumber\n",
    "FROM [Track].[TException] \n",
    "GROUP BY [TrackingNumber] \n",
    "HAVING COUNT(TrackingNumber) > 4) b\n",
    "ON a.TrackingNumber = b.TrackingNumber\n",
    "\n",
    "INNER JOIN( SELECT * \n",
    "FROM [Track].[TPerformanceData]\n",
    "WHERE TNTStatusCode NOT IN ('00,07')) c\n",
    "ON c.TrackingNumber = a.TrackingNumber\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#merge dataframes with definitions\n",
    "df = pd.merge(df, dimexc, left_on = 'ExcResultCode', right_on = 'ExceptionCode')\n",
    "df = pd.merge(df, dimstatus, left_on = 'TNTStatusCode', right_on = 'PerformStatusCode')\n",
    "df.shape\n",
    "#The time it took me to make these merges seamless..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['ExcDT'] = pd.to_datetime(df['ExcDT']) #Convert all dates to datetime objects\n",
    "# least_recent_date = df['ExcDT'].min()\n",
    "# recent_date = df['ExcDT'].max()\n",
    "print(\"This data timeframe ranges from \"+str(df['ExcDT'].min())+\" to \"+str(df['ExcDT'].max()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create IsLate column for binary classification\n",
    "# 1 means the package is late 0 means its on time\n",
    "df['IsLate'] = np.where(df['TNTStatusCode'].isin(['03','05','06','08']), 1, 0) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.loc[:,~df.columns.duplicated()] # remove duplicate columns from dataframe\n",
    "df = df.fillna(value = 'none') #Fill missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Filtering the dataframe in order to analyze the top occuring exception codes\n",
    "topexc = df.groupby(\"ExceptionDesc\").filter(lambda x: len(x) > 3000)\n",
    "print(len(topexc)/len(df))\n",
    "topexc.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Sunburst charts FTW\n",
    "fig = px.sunburst(topexc, path=['InducerDescription','TNTStatusCode', 'ExcResultCode'],\n",
    "                  hover_data=['ExceptionDesc','PerformDesc'])\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare Dataframe for Label Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = df.groupby('TrackingNumber').apply(lambda x: x['ExcReasonCode'].unique()) #create array with all exception codes grouped for a given tracking number\n",
    "df2 = pd.DataFrame({'TrackingNumber':df2.index, 'ExceptionCodes':df2.values.tolist()}) #turn into dataframe\n",
    "for i,row in df2.iterrows():\n",
    "    row['ExceptionCodes'] = [x for x in row['ExceptionCodes'] if x != 'none'] #Remove null values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfx = pd.merge(df2, df.drop_duplicates(subset=['TrackingNumber']), on='TrackingNumber',how = 'left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Dont remember what this cell does have fun haha, may have been a failure\n",
    "q=0\n",
    "\n",
    "def comp(x,q):\n",
    "    i=0\n",
    "    if x['ExcResultCode'] == 'none':\n",
    "        inducer = 'X'\n",
    "    else:\n",
    "        try:\n",
    "            inducer = defdict[x['ExcResultCode']]\n",
    "        except:\n",
    "            print(x['ExcResultCode'])\n",
    "            q += 1\n",
    "            pass\n",
    "        finally:\n",
    "            inducer = 'X'\n",
    "    # print(x['ExceptionDesc']+' - Inducer: '+str(result))\n",
    "    try:\n",
    "        otherexc = set([defdict[i] for i in row['ExceptionCodes']])\n",
    "    except:\n",
    "        otherexc = []\n",
    "    # other = set(otherexc)\n",
    "    # print('other inducers:')\n",
    "    # for p in otherexc: print(p)\n",
    "    for x in otherexc: \n",
    "        if x != inducer: \n",
    "            i+=1\n",
    "    # print(i)\n",
    "    return inducer, i\n",
    "\n",
    "dfx[['Inducer','test']]=dfx.apply(comp, axis=1, result_type=\"expand\")\n",
    "print(q)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing a machine learning algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df4 = pd.get_dummies(df2, columns=('ExceptionCodes'))\n",
    "df3 = df2['ExceptionCodes'].str.join('|').str.get_dummies()\n",
    "dfy = pd.concat([df2, df3], axis=1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfz = dfx[['TrackingNumber','IsLate']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfy = pd.merge(dfy, dfz, on='TrackingNumber', how='left',)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split, cross_validate\n",
    "y = dfy.IsLate\n",
    "X = dfy.drop(['TrackingNumber','IsLate','ExceptionCodes'], axis = 1)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, accuracy_score, classification_report\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rfc = RandomForestClassifier(n_estimators=50)\n",
    "rfc.fit(X_train, y_train)\n",
    "rfc_pred = rfc.predict(X_test)\n",
    "\n",
    "print(confusion_matrix(rfc_pred,y_test))\n",
    "print('Accuracy score:',accuracy_score(rfc_pred, y_test))\n",
    "print(classification_report(rfc_pred, y_test))\n",
    "\n",
    "cross_val_score_rfc = cross_validate(rfc, X_train, y_train,cv = 5,return_train_score=True)\n",
    "\n",
    "print('Cross validation train_score',cross_val_score_rfc['train_score'].mean())\n",
    "print('Cross validation test_score',cross_val_score_rfc['test_score'].mean())\n",
    "winsound.Beep(440, 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#So what exception codes have the greatest predictive power?\n",
    "feature_imp = rfc.feature_importances_.round(3)\n",
    "df_feature_imp = pd.DataFrame({'Columns':pd.Series(X.columns),'Importance': feature_imp})\n",
    "df_feature_imp = df_feature_imp.sort_values(by=['Importance'], ascending=False)\n",
    "dff = df_feature_imp.nlargest(20,'Importance')\n",
    "\n",
    "px.bar(dff,x='Columns',y='Importance',color='Importance')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
